{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Exercise: Setting Up a Hadoop Cluster on Your Local Machine\n",
    "\n",
    "**Objective**: By the end of this hands-on exercise, students will have set up a single-node Hadoop cluster on an Ubuntu machine, understand the basics of the Hadoop ecosystem (HDFS, MapReduce, YARN), and run a simple MapReduce job and an Apache Spark application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction to Big Data and Distributed Systems\n",
    "\n",
    "**Description**: Big Data refers to large and complex datasets that traditional data processing software cannot handle efficiently. Distributed computing involves dividing these large data sets into smaller chunks and processing them on multiple machines simultaneously.\n",
    "\n",
    "Key Concepts:\n",
    "- Volume: The size of the data.\n",
    "\n",
    "- Velocity: The speed at which data is generated.\n",
    "\n",
    "- Variety: Different types of data (structured, unstructured).\n",
    "\n",
    "- Veracity: Uncertainty of data.\n",
    "\n",
    "Distributed Systems:\n",
    "- A cluster of machines (nodes) works together to process data faster.\n",
    "\n",
    "- Hadoop is one such system built for distributed processing of large data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting Up a Hadoop Cluster on Ubuntu\n",
    "\n",
    "**Pre-requisites**:\n",
    "- Ubuntu (Virtual Machine or Native Installation)\n",
    "\n",
    "- Java installed (`sudo apt install openjdk-8-jdk`)\n",
    "\n",
    "- SSH setup (`sudo apt install openssh-server`)\n",
    "\n",
    "\n",
    "**Installation**:\n",
    "- Run the `hadoop-install-script.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Hadoop Ecosystem: HDFS, MapReduce, YARN\n",
    "### Task 1: Introduction to HDFS (Hadoop Distributed File System)\n",
    "\n",
    "- HDFS: The distributed file system for storing large datasets across multiple nodes.\n",
    "\n",
    "1. Create a Directory in HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ hdfs dfs -mkdir /user\n",
    "$ hdfs dfs -mkdir /user/datatech-labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. List Files in HDFS: Check the files in HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: MapReduce Overview. Implement a Simple MapReduce Job\n",
    "- MapReduce: A programming model used for processing large data sets with a distributed algorithm on a cluster.\n",
    "\n",
    "1. Create a text file (word count example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ echo -e \"Hello\\nWorld\\nHello\\nHadoop\" > words.txt\n",
    "$ hdfs dfs -put words.txt /user/datatech-labs/words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a Python MapReduce Job: Look at the Python file named `wordcount_mapRed.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run the Job: Execute the MapReduce job on the dataset in HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ python3 wordcount_mapRed.py -r hadoop hdfs:///user/datatech-labs/words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
